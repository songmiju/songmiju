## 크롤링코드
get_ipython().system('pip install selenium')


from selenium import webdriver
from bs4 import BeautifulSoup
import time
import re
import pandas as pd


url = "https://play.google.com/store/apps/details?id=com.kakao.talk&showAllReviews=true"   # 접속하고자하는 url
driverPath = "C:\\Users\\stat\\Downloads\\chromedriver_win32\\chromedriver.exe" # Chrome Driver path
driver = webdriver.Chrome(driverPath)   # Open Chrome 
driver.get(url)    #Enter the url



SCROLL_PAUSE_TIME = 3.5 #대기시간 지정

last_height = driver.execute_script("return document.body.scrollHeight")

while True:
    #(1) 4번의  스크롤링을 하도록 한다
    for i in range(4):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_PAUSE_TIME)

    #(2) 더보기를 클릭하도록 해준다 
    driver.find_element_by_xpath("//span[@class='RveJvd snByac']").click()
    
    #(3) 종료 조건
    new_height = driver.execute_script("return document.body.scrollHeight")
    if new_height == last_height:
        break
    last_height = new_height

reviews = driver.find_elements_by_xpath("//span[@jsname='bN97Pc']")
reviews


dates = driver.find_elements_by_xpath("//span[@class='p2TkOb']")
dates

likes = driver.find_elements_by_xpath("//div[@aria-label='이 리뷰가 유용하다는 평가를 받은 횟수입니다.']")
likes

stars = driver.find_elements_by_xpath("//span[@class='nt2C1d']/div[@class='pf5lIe']/div[@role='img']")
stars  


res_dict = []
#append를 이용하여 위에서 가져온 date, star, like, review를 합쳐준다.
for i in range(len(reviews)):
    res_dict.append({
        'DATE' : dates[i].text, #하나씩 들어가서 가져온다.
        'STAR' : stars[i].get_attribute('aria-label'),
        'LIKE' : likes[i].text,
        'REVIEW' : reviews[i].text
    })
    
res_df = pd.DataFrame(res_dict)
res_df


# In[ ]:


res_df.to_csv("카카오 앱 리뷰 .csv")
